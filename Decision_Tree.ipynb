{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree"
      ],
      "metadata": {
        "id": "Qtik0TcDEAJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1"
      ],
      "metadata": {
        "id": "mnyX_EUWEHlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->A Decision Tree is a popular supervised machine learning algorithm used for both classification and regression tasks. It works like a flowchart-style structure where:\n",
        "\n",
        "Internal nodes represent decisions based on features,\n",
        "\n",
        "Branches represent the outcomes of those decisions,\n",
        "\n",
        "Leaf nodes represent final predictions or outcomes (like a class label or a continuous value).\n",
        "\n",
        "🔍 How a Decision Tree Works:\n",
        "Start with the entire dataset as the root.\n",
        "\n",
        "Select the best feature to split the data based on a certain criterion:\n",
        "\n",
        "For classification: use criteria like Gini Impurity, Entropy, or Information Gain.\n",
        "\n",
        "For regression: use Mean Squared Error (MSE) or Variance Reduction.\n",
        "\n",
        "Split the dataset into subsets so that similar outcomes are grouped together.\n",
        "\n",
        "Repeat the process recursively for each child node until one of the following conditions is met:\n",
        "\n",
        "All samples at a node belong to the same class.\n",
        "\n",
        "Maximum depth is reached.\n",
        "\n",
        "Minimum number of samples per leaf node is reached.\n",
        "\n",
        "No further gain from splitting.\n",
        "\n",
        "Make predictions:\n",
        "\n",
        "For classification: the class label of a leaf node is the prediction.\n",
        "\n",
        "For regression: the average value in the leaf node is the prediction.\n",
        "\n",
        "🧠 Example (Classification):\n",
        "Say you’re trying to classify whether someone will buy a computer based on age and income:\n",
        "\n",
        "yaml\n",
        "Copy\n",
        "Edit\n",
        "             [Age < 30?]\n",
        "               /     \\\n",
        "           Yes        No\n",
        "         [Income?]   Buy = Yes\n",
        "        /      \\\n",
        "     Low       High\n",
        "   Buy=No     Buy=Yes\n",
        "This tree says:\n",
        "\n",
        "If Age < 30 and Income is Low → No\n",
        "\n",
        "If Age < 30 and Income is High → Yes\n",
        "\n",
        "If Age ≥ 30 → Yes\n",
        "\n",
        "✅ Pros:\n",
        "Easy to interpret and visualize\n",
        "\n",
        "Requires little data preprocessing\n",
        "\n",
        "Handles both numerical and categorical data\n",
        "\n",
        "❌ Cons:\n",
        "Prone to overfitting\n",
        "\n",
        "Can be unstable (small changes in data can lead to different trees)\n",
        "\n",
        "Greedy algorithm: doesn't always find the global optimum"
      ],
      "metadata": {
        "id": "K5P_KyMfEHik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2"
      ],
      "metadata": {
        "id": "mEo53nBCEHfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->In Decision Trees, impurity measures are used to quantify how \"mixed\" or \"impure\" a node is with respect to the target classes (for classification) or the variance of the target values (for regression). They help the algorithm decide which feature and threshold to use when splitting the data at each node.\n",
        "\n",
        "Impurity Measures for Classification:\n",
        "Gini Impurity:\n",
        "\n",
        "Measures the probability of a randomly chosen element being incorrectly classified.\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(t)=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "where\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of class\n",
        "𝑖\n",
        "i instances in node\n",
        "𝑡\n",
        "t, and\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "\n",
        "Entropy (Information Gain):\n",
        "\n",
        "Comes from information theory; measures the amount of \"disorder\" or uncertainty.\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(t)=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Splits are chosen to maximize information gain, which is the reduction in entropy.\n",
        "\n",
        "Classification Error (used less often):\n",
        "\n",
        "Measures the proportion of misclassified samples in a node.\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝐸\n",
        "𝑟\n",
        "𝑟\n",
        "𝑜\n",
        "𝑟\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "max\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Error(t)=1−max(p\n",
        "i\n",
        "​\n",
        " )\n",
        "where\n",
        "max\n",
        "⁡\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "max(p\n",
        "i\n",
        "​\n",
        " ) is the proportion of the majority class in node\n",
        "𝑡\n",
        "t.\n",
        "\n",
        "Impurity Measure for Regression:\n",
        "Variance Reduction:\n",
        "\n",
        "Measures how much the variance of the target variable decreases after a split.\n",
        "\n",
        "Formula (for variance in node\n",
        "𝑡\n",
        "t):\n",
        "\n",
        "𝑉\n",
        "𝑎\n",
        "𝑟\n",
        "(\n",
        "𝑡\n",
        ")\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "Var(t)=\n",
        "N\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "N\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "ˉ\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "The best split is the one that minimizes the weighted average of variances of the child nodes.\n",
        "\n",
        "Mean Absolute Deviation (less common):\n",
        "\n",
        "Uses absolute differences rather than squared.\n",
        "\n",
        "Can be more robust to outliers."
      ],
      "metadata": {
        "id": "nMzoW9JpEHc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "iNE1hXY1EHZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->The Gini Impurity is a measure used in decision trees (e.g., in the CART algorithm) to quantify how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the set.\n",
        "\n",
        "Mathematical Formula for Gini Impurity\n",
        "For a dataset with\n",
        "𝐶\n",
        "C classes, the Gini impurity\n",
        "𝐺\n",
        "G is defined as:\n",
        "\n",
        "𝐺\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "G=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes,\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability (or proportion) of choosing an item of class\n",
        "𝑖\n",
        "i in the dataset.\n",
        "\n",
        "Example:\n",
        "If a node contains:\n",
        "\n",
        "3 examples of class A,\n",
        "\n",
        "2 examples of class B,\n",
        "\n",
        "Then:\n",
        "\n",
        "𝑝\n",
        "𝐴\n",
        "=\n",
        "3\n",
        "5\n",
        "=\n",
        "0.6\n",
        "p\n",
        "A\n",
        "​\n",
        " =\n",
        "5\n",
        "3\n",
        "​\n",
        " =0.6\n",
        "\n",
        "𝑝\n",
        "𝐵\n",
        "=\n",
        "2\n",
        "5\n",
        "=\n",
        "0.4\n",
        "p\n",
        "B\n",
        "​\n",
        " =\n",
        "5\n",
        "2\n",
        "​\n",
        " =0.4\n",
        "\n",
        "𝐺\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.6\n",
        "2\n",
        "+\n",
        "0.4\n",
        "2\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "(\n",
        "0.36\n",
        "+\n",
        "0.16\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "0.52\n",
        "=\n",
        "0.48\n",
        "G=1−(0.6\n",
        "2\n",
        " +0.4\n",
        "2\n",
        " )=1−(0.36+0.16)=1−0.52=0.48\n",
        "This impurity value tells us how mixed the classes are at that node"
      ],
      "metadata": {
        "id": "MBIxxwyGEHXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4"
      ],
      "metadata": {
        "id": "b6Mk9QZTEHUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->The mathematical formula for entropy depends on the context—typically information theory or thermodynamics. Here's both:\n",
        "\n",
        "1. Entropy in Information Theory (Shannon Entropy)\n",
        "This measures the uncertainty or information content of a random variable:\n",
        "\n",
        "𝐻\n",
        "(\n",
        "𝑋\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑝\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ")\n",
        "log\n",
        "⁡\n",
        "𝑏\n",
        "𝑝\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ")\n",
        "H(X)=−\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " p(x\n",
        "i\n",
        "​\n",
        " )log\n",
        "b\n",
        "​\n",
        " p(x\n",
        "i\n",
        "​\n",
        " )\n",
        "𝐻\n",
        "(\n",
        "𝑋\n",
        ")\n",
        "H(X): Entropy of the random variable\n",
        "𝑋\n",
        "X\n",
        "\n",
        "𝑝\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ")\n",
        "p(x\n",
        "i\n",
        "​\n",
        " ): Probability of outcome\n",
        "𝑥\n",
        "𝑖\n",
        "x\n",
        "i\n",
        "​\n",
        "\n",
        "\n",
        "𝑛\n",
        "n: Number of possible outcomes\n",
        "\n",
        "log\n",
        "⁡\n",
        "𝑏\n",
        "log\n",
        "b\n",
        "​\n",
        " : Logarithm with base\n",
        "𝑏\n",
        "b, usually:\n",
        "\n",
        "Base 2 → bits\n",
        "\n",
        "Base\n",
        "𝑒\n",
        "e → nats\n",
        "\n",
        "Base 10 → bans\n",
        "\n",
        "2. Entropy in Thermodynamics (Boltzmann Entropy)\n",
        "This describes the number of microscopic configurations (microstates) corresponding to a thermodynamic system's macroscopic state:\n",
        "\n",
        "𝑆\n",
        "=\n",
        "𝑘\n",
        "𝐵\n",
        "ln\n",
        "⁡\n",
        "Ω\n",
        "S=k\n",
        "B\n",
        "​\n",
        " lnΩ\n",
        "𝑆\n",
        "S: Entropy\n",
        "\n",
        "𝑘\n",
        "𝐵\n",
        "k\n",
        "B\n",
        "​\n",
        " : Boltzmann constant (\n",
        "1.380649\n",
        "×\n",
        "10\n",
        "−\n",
        "23\n",
        " J/K\n",
        "1.380649×10\n",
        "−23\n",
        "  J/K)\n",
        "\n",
        "Ω\n",
        "Ω: Number of microstates\n",
        "\n",
        "ln\n",
        "⁡\n",
        "ln: Natural logarithm"
      ],
      "metadata": {
        "id": "JJMwdykbEHRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5"
      ],
      "metadata": {
        "id": "UzxUvYQTEHOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Information Gain (IG) is a metric used in Decision Trees to measure the effectiveness of an attribute in classifying a dataset. It quantifies the reduction in entropy (or uncertainty) achieved by splitting the data based on an attribute.\n",
        "\n",
        "Key Concepts:\n",
        "1. Entropy:\n",
        "Entropy measures the impurity or disorder in the dataset. For a dataset\n",
        "𝐷\n",
        "D, the entropy is calculated as:\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(D)=−\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of class\n",
        "𝑖\n",
        "i in the dataset.\n",
        "\n",
        "𝑛\n",
        "n is the number of classes.\n",
        "\n",
        "2. Information Gain:\n",
        "Information Gain tells us how much entropy is reduced by partitioning the data on an attribute\n",
        "𝐴\n",
        "A:\n",
        "\n",
        "Information Gain\n",
        "(\n",
        "𝐷\n",
        ",\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑣\n",
        "∈\n",
        "Values\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "⋅\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        "𝑣\n",
        ")\n",
        "Information Gain(D,A)=Entropy(D)−\n",
        "v∈Values(A)\n",
        "∑\n",
        "​\n",
        "  \n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        " ⋅Entropy(D\n",
        "v\n",
        "​\n",
        " )\n",
        "where:\n",
        "\n",
        "𝐷\n",
        "𝑣\n",
        "D\n",
        "v\n",
        "​\n",
        "  is the subset of\n",
        "𝐷\n",
        "D where attribute\n",
        "𝐴\n",
        "A has value\n",
        "𝑣\n",
        "v.\n",
        "\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣ is the size of that subset.\n",
        "\n",
        "How is Information Gain Used in Decision Trees?\n",
        "Attribute Selection:\n",
        "At each node in the Decision Tree, the algorithm evaluates all attributes and selects the one with the highest Information Gain to split the data. This ensures that each split leads to the most significant reduction in uncertainty.\n",
        "\n",
        "Tree Growth:\n",
        "\n",
        "The process is repeated recursively.\n",
        "\n",
        "At each node, the best attribute is selected until the tree fully classifies the data or meets a stopping condition (e.g., depth limit, minimum samples per leaf).\n",
        "\n",
        "Example:\n",
        "Imagine a dataset with the target \"Play Tennis\" (Yes/No) and an attribute \"Outlook\" (Sunny, Overcast, Rain). The decision tree will:\n",
        "\n",
        "Calculate entropy of the target.\n",
        "\n",
        "Compute entropy for each value of \"Outlook\".\n",
        "\n",
        "Compute the weighted average entropy after the split.\n",
        "\n",
        "Subtract this from the original entropy to get Information Gain.\n",
        "\n",
        "Choose \"Outlook\" if it gives the highest gain."
      ],
      "metadata": {
        "id": "DoJDGg-REHLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6"
      ],
      "metadata": {
        "id": "E0qpY51fEHIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Gini Impurity and Entropy are both metrics used to measure the \"purity\" or \"impurity\" of a dataset at a node in a Decision Tree. They're used to decide how the tree should split the data at each step.\n",
        "\n",
        "📊 1. Gini Impurity\n",
        "Gini Impurity measures the likelihood of incorrectly classifying a randomly chosen element if it was randomly labeled according to the class distribution in the node.\n",
        "\n",
        "🧮 Formula:\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini=1−\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability of class\n",
        "𝑖\n",
        "i\n",
        "\n",
        "𝑛\n",
        "n is the number of classes\n",
        "\n",
        "🧠 Intuition:\n",
        "Gini = 0 → All elements are of one class (pure).\n",
        "\n",
        "Gini approaches 0.5 (for binary classes) when classes are equally mixed (impure).\n",
        "\n",
        "🔥 2. Entropy (Information Gain)\n",
        "Entropy measures the amount of uncertainty or disorder in the dataset. It comes from information theory and is used in ID3/C4.5 decision trees.\n",
        "\n",
        "🧮 Formula:\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy=−\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability of class\n",
        "𝑖\n",
        "i\n",
        "\n",
        "🧠 Intuition:\n",
        "Entropy = 0 → All data is pure (only one class).\n",
        "\n",
        "Entropy is highest (for binary) when classes are split 50/50.\n",
        "\n",
        "⚖️ Comparison Table:\n",
        "Feature\tGini Impurity\tEntropy (Information Gain)\n",
        "Range\t0 (pure) to ~0.5 (impure)\t0 (pure) to 1 (maximum disorder)\n",
        "Computation\tFaster (no log calculation)\tSlightly slower (log involved)\n",
        "Bias\tTends to isolate the most frequent class\tMay produce more balanced trees\n",
        "Used in\tCART algorithm (scikit-learn)\tID3, C4.5, and others\n",
        "Interpretation\tProbability of misclassification\tAmount of information (bits) needed\n",
        "\n",
        "🧪 Example (Binary Class):\n",
        "Assume we have 4 items:\n",
        "\n",
        "2 of Class A, 2 of Class B\n",
        "\n",
        "Then:\n",
        "\n",
        "Gini = 1 − (0.5² + 0.5²) = 0.5\n",
        "\n",
        "Entropy = −(0.5 log₂ 0.5 + 0.5 log₂ 0.5) = 1.0\n",
        "\n",
        "Both indicate maximum impurity."
      ],
      "metadata": {
        "id": "7Vk2RfAFEHF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7"
      ],
      "metadata": {
        "id": "N3jzBbcfEHC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->ChatGPT said:\n",
        "The mathematical explanation behind Decision Trees lies in recursively splitting a dataset into subsets based on a feature that results in the largest improvement in a certain impurity measure (e.g., Gini, Entropy, Variance). Here's how it works step by step:\n",
        "\n",
        "🌳 Decision Tree (Mathematical Framework)\n",
        "1. Problem Setting\n",
        "Given a dataset:\n",
        "\n",
        "𝐷\n",
        "=\n",
        "{\n",
        "(\n",
        "𝑥\n",
        "1\n",
        ",\n",
        "𝑦\n",
        "1\n",
        ")\n",
        ",\n",
        "(\n",
        "𝑥\n",
        "2\n",
        ",\n",
        "𝑦\n",
        "2\n",
        ")\n",
        ",\n",
        "…\n",
        ",\n",
        "(\n",
        "𝑥\n",
        "𝑛\n",
        ",\n",
        "𝑦\n",
        "𝑛\n",
        ")\n",
        "}\n",
        "D={(x\n",
        "1\n",
        "​\n",
        " ,y\n",
        "1\n",
        "​\n",
        " ),(x\n",
        "2\n",
        "​\n",
        " ,y\n",
        "2\n",
        "​\n",
        " ),…,(x\n",
        "n\n",
        "​\n",
        " ,y\n",
        "n\n",
        "​\n",
        " )}\n",
        "\n",
        "Each\n",
        "𝑥\n",
        "𝑖\n",
        "=\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        "1\n",
        ",\n",
        "𝑥\n",
        "𝑖\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑥\n",
        "𝑖\n",
        "𝑑\n",
        ")\n",
        "∈\n",
        "𝑅\n",
        "𝑑\n",
        "x\n",
        "i\n",
        "​\n",
        " =(x\n",
        "i\n",
        "1\n",
        "​\n",
        " ,x\n",
        "i\n",
        "2\n",
        "​\n",
        " ,…,x\n",
        "i\n",
        "d\n",
        "​\n",
        " )∈R\n",
        "d\n",
        "  is a feature vector\n",
        "\n",
        "Each\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is a class label (classification) or real value (regression)\n",
        "\n",
        "2. Recursive Partitioning (Top-Down Splitting)\n",
        "At each node:\n",
        "\n",
        "For each feature\n",
        "𝑗\n",
        "j and each possible split point\n",
        "𝑠\n",
        "s:\n",
        "\n",
        "Split data into:\n",
        "\n",
        "𝐷\n",
        "𝑙\n",
        "𝑒\n",
        "𝑓\n",
        "𝑡\n",
        "=\n",
        "{\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ",\n",
        "𝑦\n",
        "𝑖\n",
        ")\n",
        ":\n",
        "𝑥\n",
        "𝑖\n",
        "𝑗\n",
        "≤\n",
        "𝑠\n",
        "}\n",
        "D\n",
        "left\n",
        "​\n",
        " ={(x\n",
        "i\n",
        "​\n",
        " ,y\n",
        "i\n",
        "​\n",
        " ):x\n",
        "i\n",
        "j\n",
        "​\n",
        " ≤s}\n",
        "\n",
        "𝐷\n",
        "𝑟\n",
        "𝑖\n",
        "𝑔\n",
        "ℎ\n",
        "𝑡\n",
        "=\n",
        "{\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ",\n",
        "𝑦\n",
        "𝑖\n",
        ")\n",
        ":\n",
        "𝑥\n",
        "𝑖\n",
        "𝑗\n",
        ">\n",
        "𝑠\n",
        "}\n",
        "D\n",
        "right\n",
        "​\n",
        " ={(x\n",
        "i\n",
        "​\n",
        " ,y\n",
        "i\n",
        "​\n",
        " ):x\n",
        "i\n",
        "j\n",
        "​\n",
        " >s}\n",
        "\n",
        "Compute impurity of the split:\n",
        "\n",
        "For classification, impurity\n",
        "𝐼\n",
        "I could be Gini or Entropy\n",
        "\n",
        "For regression, impurity is typically Variance\n",
        "\n",
        "🧮 Impurity Reduction:\n",
        "Let:\n",
        "\n",
        "𝐼\n",
        "𝑝\n",
        "𝑎\n",
        "𝑟\n",
        "𝑒\n",
        "𝑛\n",
        "𝑡\n",
        "I\n",
        "parent\n",
        "​\n",
        " : impurity before split\n",
        "\n",
        "𝐼\n",
        "𝑙\n",
        "𝑒\n",
        "𝑓\n",
        "𝑡\n",
        ",\n",
        "𝐼\n",
        "𝑟\n",
        "𝑖\n",
        "𝑔\n",
        "ℎ\n",
        "𝑡\n",
        "I\n",
        "left\n",
        "​\n",
        " ,I\n",
        "right\n",
        "​\n",
        " : impurity in child nodes\n",
        "\n",
        "𝑁\n",
        ",\n",
        "𝑁\n",
        "𝐿\n",
        ",\n",
        "𝑁\n",
        "𝑅\n",
        "N,N\n",
        "L\n",
        "​\n",
        " ,N\n",
        "R\n",
        "​\n",
        " : number of samples in parent and children\n",
        "\n",
        "Then:\n",
        "\n",
        "Information Gain\n",
        "=\n",
        "𝐼\n",
        "𝑝\n",
        "𝑎\n",
        "𝑟\n",
        "𝑒\n",
        "𝑛\n",
        "𝑡\n",
        "−\n",
        "(\n",
        "𝑁\n",
        "𝐿\n",
        "𝑁\n",
        "𝐼\n",
        "𝑙\n",
        "𝑒\n",
        "𝑓\n",
        "𝑡\n",
        "+\n",
        "𝑁\n",
        "𝑅\n",
        "𝑁\n",
        "𝐼\n",
        "𝑟\n",
        "𝑖\n",
        "𝑔\n",
        "ℎ\n",
        "𝑡\n",
        ")\n",
        "Information Gain=I\n",
        "parent\n",
        "​\n",
        " −(\n",
        "N\n",
        "N\n",
        "L\n",
        "​\n",
        "\n",
        "​\n",
        " I\n",
        "left\n",
        "​\n",
        " +\n",
        "N\n",
        "N\n",
        "R\n",
        "​\n",
        "\n",
        "​\n",
        " I\n",
        "right\n",
        "​\n",
        " )\n",
        "Choose the split (feature\n",
        "𝑗\n",
        "j, threshold\n",
        "𝑠\n",
        "s) that maximizes information gain.\n",
        "\n",
        "3. Stopping Criteria\n",
        "A node becomes a leaf when:\n",
        "\n",
        "All samples belong to the same class (classification)\n",
        "\n",
        "Max depth is reached\n",
        "\n",
        "Node contains fewer than a minimum number of samples\n",
        "\n",
        "No significant impurity reduction is possible\n",
        "\n",
        "4. Prediction\n",
        "For classification: majority vote in the leaf node\n",
        "\n",
        "𝑦\n",
        "^\n",
        "=\n",
        "arg\n",
        "⁡\n",
        "max\n",
        "⁡\n",
        "𝑐\n",
        "1\n",
        "𝑁\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "∑\n",
        "𝑖\n",
        "∈\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "1\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "=\n",
        "𝑐\n",
        ")\n",
        "y\n",
        "^\n",
        "​\n",
        " =arg\n",
        "c\n",
        "max\n",
        "​\n",
        "  \n",
        "N\n",
        "leaf\n",
        "​\n",
        "\n",
        "1\n",
        "​\n",
        "  \n",
        "i∈leaf\n",
        "∑\n",
        "​\n",
        " 1(y\n",
        "i\n",
        "​\n",
        " =c)\n",
        "For regression: mean of values in the leaf node\n",
        "\n",
        "𝑦\n",
        "^\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "∑\n",
        "𝑖\n",
        "∈\n",
        "𝑙\n",
        "𝑒\n",
        "𝑎\n",
        "𝑓\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "^\n",
        "​\n",
        " =\n",
        "N\n",
        "leaf\n",
        "​\n",
        "\n",
        "1\n",
        "​\n",
        "  \n",
        "i∈leaf\n",
        "∑\n",
        "​\n",
        " y\n",
        "i\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "I-2Og84UEHAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8"
      ],
      "metadata": {
        "id": "udgrlOoDEG9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Pre-pruning (also known as early stopping) is a technique used in building decision trees to prevent the tree from growing too large and overfitting the training data.\n",
        "\n",
        "🔍 Definition:\n",
        "Pre-pruning stops the tree growth early, before it perfectly classifies the training set, based on certain stopping criteria.\n",
        "\n",
        "🧠 Why Use Pre-Pruning?\n",
        "Without constraints, decision trees tend to grow deep and complex, fitting noise in the training data. Pre-pruning helps to:\n",
        "\n",
        "Improve generalization to unseen data.\n",
        "\n",
        "Reduce model complexity.\n",
        "\n",
        "Speed up training.\n",
        "\n",
        "✅ Common Pre-Pruning Criteria:\n",
        "Maximum Depth: Stop splitting if a node reaches a predefined depth.\n",
        "\n",
        "Minimum Samples per Node: Stop splitting if a node has fewer than a minimum number of samples.\n",
        "\n",
        "Minimum Information Gain (or Gini Decrease): Stop splitting if the improvement in impurity is below a threshold.\n",
        "\n",
        "Maximum Number of Nodes or Leaves: Limit the total number of nodes or leaves in the tree.\n",
        "\n",
        "📌 Example:\n",
        "Suppose you're growing a decision tree and you’ve reached a node with only 5 samples. If your pre-pruning rule says “Only split nodes with at least 10 samples,” then the algorithm will stop at that node and assign a label based on the majority class, without further splitting.\n",
        "\n",
        "🔄 Pre-Pruning vs Post-Pruning:\n",
        "Technique\tWhen Applied\tGoal\n",
        "Pre-Pruning\tDuring tree growth\tPrevent overfitting early\n",
        "Post-Pruning\tAfter full tree is grown\tPrune back overfitted parts"
      ],
      "metadata": {
        "id": "2cCNa94WG5hL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9"
      ],
      "metadata": {
        "id": "9YRgSsA3EPe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Grow the full decision tree: The tree is allowed to grow until it perfectly fits the training data (or nearly so), potentially overfitting.\n",
        "\n",
        "Prune back the tree: Nodes (especially leaf nodes or small subtrees) are removed or replaced with leaves if doing so improves performance on a validation set or based on a statistical criterion.\n",
        "\n",
        "🧠 Why Prune?\n",
        "Deep trees can memorize training data (overfitting) and perform poorly on unseen data.\n",
        "\n",
        "Pruning simplifies the tree, making it more robust and easier to interpret.\n",
        "\n",
        "🔧 How Is It Done?\n",
        "There are a few strategies:\n",
        "\n",
        "Reduced error pruning: Remove a subtree if the performance on a validation set does not worsen.\n",
        "\n",
        "Cost-complexity pruning (used in CART):\n",
        "\n",
        "𝑅\n",
        "𝛼\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "=\n",
        "𝑅\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "+\n",
        "𝛼\n",
        "⋅\n",
        "∣\n",
        "𝑇\n",
        "∣\n",
        "R\n",
        "α\n",
        "​\n",
        " (T)=R(T)+α⋅∣T∣\n",
        "𝑅\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "R(T): Error of the tree on training data\n",
        "\n",
        "∣\n",
        "𝑇\n",
        "∣\n",
        "∣T∣: Number of terminal nodes (leaves)\n",
        "\n",
        "𝛼\n",
        "α: Complexity parameter controlling the trade-off between accuracy and simplicity\n",
        "\n",
        "✅ Benefits\n",
        "Improves generalization.\n",
        "\n",
        "Reduces model size and complexity.\n",
        "\n",
        "Makes trees easier to interpret.\n",
        "\n"
      ],
      "metadata": {
        "id": "YXTqZrELEPcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10"
      ],
      "metadata": {
        "id": "QrFCzrtXEPZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Difference Between Pre-Pruning and Post-Pruning in Decision Trees\n",
        "Pruning is used in decision trees to prevent overfitting, which happens when the tree learns noise or irrelevant patterns in the training data. There are two main strategies:\n",
        "\n",
        "1. Pre-Pruning (Early Stopping)\n",
        "Definition:\n",
        "Pre-pruning stops the tree from growing once it meets certain conditions during training.\n",
        "\n",
        "How it works:\n",
        "\n",
        "It halts further splitting if:\n",
        "\n",
        "The number of samples in a node is below a threshold.\n",
        "\n",
        "The Information Gain from a split is too small.\n",
        "\n",
        "The tree reaches a maximum depth.\n",
        "\n",
        "A statistical test (e.g. chi-square) finds the split is not significant.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Saves time and resources during training.\n",
        "\n",
        "Reduces the risk of overfitting early.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "May stop the tree too early and miss important patterns.\n",
        "\n",
        "Can lead to underfitting.\n",
        "\n",
        "2. Post-Pruning (Prune After Full Tree Growth)\n",
        "Definition:\n",
        "Post-pruning allows the tree to grow fully, then prunes back branches that don’t improve performance on validation data.\n",
        "\n",
        "How it works:\n",
        "\n",
        "Build a complete tree.\n",
        "\n",
        "Evaluate subtrees or leaf nodes using a validation set or cross-validation.\n",
        "\n",
        "Remove branches that do not significantly improve predictive accuracy.\n",
        "\n",
        "Techniques:\n",
        "\n",
        "Reduced error pruning.\n",
        "\n",
        "Cost-complexity pruning (used in CART).\n",
        "\n",
        "Advantages:\n",
        "\n",
        "More accurate as it evaluates based on real performance.\n",
        "\n",
        "Less chance of underfitting.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "More computationally expensive.\n",
        "\n",
        "Requires a separate validation set or cross-validation."
      ],
      "metadata": {
        "id": "mMykZ2OLEPXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11"
      ],
      "metadata": {
        "id": "q6fFtghqEPUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->A Decision Tree Regressor is a type of Decision Tree used specifically for regression tasks, where the goal is to predict a continuous value rather than a class label (which is the case for classification tasks).\n",
        "\n",
        "In simpler terms, a Decision Tree Regressor splits the data into regions where the target variable (the value we want to predict) is as similar as possible within each region. The model then predicts the average value of the target variable for the data points in a particular region or leaf node.\n",
        "\n",
        "🧠 How It Works:\n",
        "Splitting the data: The algorithm selects the best feature (similar to classification) to split the data. However, instead of maximizing class purity (like in classification), it minimizes the variance of the target variable in each subset.\n",
        "\n",
        "Calculating Variance: At each split, the model looks at how much the target values deviate from the mean in that split. It tries to make the data in each branch more homogeneous by minimizing the variance within the groups.\n",
        "\n",
        "Stopping criteria: Just like in classification, the splitting continues recursively until a stopping criterion is met, such as:\n",
        "\n",
        "Reaching a predefined maximum depth of the tree.\n",
        "\n",
        "Having a minimum number of samples in a node.\n",
        "\n",
        "Achieving a minimum variance (no significant gain from further splitting).\n",
        "\n",
        "Prediction: Once the tree is built, a new data point is passed down the tree to a leaf node. The predicted value is the mean value of the target variable for all the data points that fall into that leaf node.\n",
        "\n",
        "🔍 Example:\n",
        "Let’s say we want to predict the house price based on certain features like size and location.\n",
        "\n",
        "The Decision Tree Regressor might:\n",
        "\n",
        "First, split the data based on the feature size (e.g., size ≤ 2000 sq ft).\n",
        "\n",
        "Then, in each branch, it further splits based on location or other features.\n",
        "\n",
        "Eventually, the model predicts the average house price for each leaf node.\n",
        "\n",
        "🧮 Mathematical Approach:\n",
        "The splitting criterion in regression trees is usually based on variance reduction. The most common measure of variance is the Mean Squared Error (MSE), calculated as:\n",
        "\n",
        "𝑀\n",
        "𝑆\n",
        "𝐸\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "^\n",
        ")\n",
        "2\n",
        "MSE=\n",
        "N\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "N\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "^\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is the true value,\n",
        "\n",
        "𝑦\n",
        "^\n",
        "y\n",
        "^\n",
        "​\n",
        "  is the predicted value (mean of target values in the leaf node),\n",
        "\n",
        "𝑁\n",
        "N is the number of samples in the node.\n",
        "\n",
        "The algorithm chooses the feature and threshold that minimizes the variance (MSE) after splitting.\n",
        "\n",
        "📈 Advantages of Decision Tree Regressor:\n",
        "Interpretability: The model is easy to understand and visualize, as it makes decisions based on simple questions about the data.\n",
        "\n",
        "No feature scaling required: Unlike linear regression, decision trees don’t require normalization or scaling of features.\n",
        "\n",
        "Handles non-linear relationships: It can model complex, non-linear relationships in data.\n",
        "\n",
        "Handles missing data: Decision trees can handle missing values by splitting on the available features.\n",
        "\n",
        "❌ Disadvantages of Decision Tree Regressor:\n",
        "Overfitting: Decision Trees tend to overfit the data, especially when the tree is deep. This means they may perform well on training data but poorly on new, unseen data.\n",
        "\n",
        "Instability: Small changes in the data can result in a very different tree structure.\n",
        "\n",
        "Bias towards features with more categories: Decision Trees may favor features with more categories or higher values if not properly tuned."
      ],
      "metadata": {
        "id": "mocgOLiKEPRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12"
      ],
      "metadata": {
        "id": "x3HMZfgTEPPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Advantages of Decision Trees\n",
        "Easy to Understand and Interpret:\n",
        "\n",
        "Decision Trees are easy to visualize and interpret, which makes them useful for explaining decisions to non-experts.\n",
        "\n",
        "The structure is intuitive: the tree-like structure shows how data is split at each node based on a feature value.\n",
        "\n",
        "No Feature Scaling Required:\n",
        "\n",
        "Decision Trees do not require normalization or standardization of data. They work directly with raw features, making them easy to implement without preprocessing steps.\n",
        "\n",
        "Can Handle Both Categorical and Numerical Data:\n",
        "\n",
        "Decision Trees can handle both continuous (numerical) and categorical data without needing conversion.\n",
        "\n",
        "Non-Linear Relationships:\n",
        "\n",
        "Unlike linear models (e.g., logistic regression), Decision Trees can model non-linear relationships between features and target variables. They work well for datasets where the relationships between features and outcomes are complex.\n",
        "\n",
        "Feature Selection:\n",
        "\n",
        "Decision Trees perform automatic feature selection by choosing the most informative features at each step, which can help reduce the dimensionality of the dataset.\n",
        "\n",
        "Versatile:\n",
        "\n",
        "They can be used for both classification (predicting categorical labels) and regression (predicting continuous values).\n",
        "\n",
        "Handles Missing Data:\n",
        "\n",
        "Some tree algorithms (like CART) can handle missing values in the data by splitting based on the available data.\n",
        "\n",
        "Disadvantages of Decision Trees\n",
        "Overfitting:\n",
        "\n",
        "Decision Trees are prone to overfitting, especially with deep trees. This means that they can memorize the training data, which leads to poor generalization to unseen data.\n",
        "\n",
        "Pruning (removing branches) or limiting tree depth is required to control overfitting.\n",
        "\n",
        "Instability:\n",
        "\n",
        "Small changes in the data can result in a completely different tree structure. This is because Decision Trees are highly sensitive to the data and may exhibit high variance.\n",
        "\n",
        "Greedy Nature:\n",
        "\n",
        "The algorithm is greedy, meaning it makes the best decision at each node without considering the global optimum. This can lead to suboptimal splits in some cases.\n",
        "\n",
        "Bias Toward Features with More Levels:\n",
        "\n",
        "Decision Trees can be biased toward features with more categories or levels. For example, categorical features with many unique values might dominate the tree-building process, leading to overfitting.\n",
        "\n",
        "Difficulty in Modeling Smooth Decision Boundaries:\n",
        "\n",
        "Decision Trees create axis-aligned decision boundaries, meaning they make decisions based on single feature thresholds. They struggle to capture smooth or curved decision boundaries, unlike models like Support Vector Machines (SVM) or neural networks.\n",
        "\n",
        "Lack of Robustness:\n",
        "\n",
        "Decision Trees can be sensitive to noise in the data. A small amount of noise can significantly impact the structure of the tree, reducing the model's accuracy.\n",
        "\n",
        "Computational Cost:\n",
        "\n",
        "Building a Decision Tree can be computationally expensive, especially with large datasets, as it involves searching through all possible splits for each feature."
      ],
      "metadata": {
        "id": "GWZP1X4MEPL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13"
      ],
      "metadata": {
        "id": "r8PHNE7bEUIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Handling missing values in decision trees is an important aspect of model training. Different decision tree algorithms have different strategies for dealing with missing values, but here are some common approaches:\n",
        "\n",
        "1. Ignore the Missing Value During the Split:\n",
        "Some decision tree algorithms simply ignore the data points with missing values for a particular split. These samples won't contribute to the decision-making process at that point in the tree, but they are kept in the dataset for future splits.\n",
        "\n",
        "For example, if you're splitting on a feature, and some of the data points have missing values for that feature, the algorithm may choose to only split on the available data, leaving the missing ones out for that split. These instances will be handled later in the process (often through other strategies).\n",
        "\n",
        "2. Impute the Missing Values (Replacement with Estimated Values):\n",
        "Before or during training, missing values can be filled (or imputed) using various strategies. Common imputation methods include:\n",
        "\n",
        "Mean/Median/Mode Imputation: For continuous features, the missing value might be replaced by the mean or median of the feature. For categorical features, the missing value could be replaced by the most frequent category (mode).\n",
        "\n",
        "Predictive Imputation: Another approach is to use other features to predict the missing value, using models such as linear regression or even another decision tree.\n",
        "\n",
        "3. Surrogate Splits (Handling Missing Data During Tree Building):\n",
        "Some decision tree algorithms, like CART (Classification and Regression Trees), can use surrogate splits to handle missing values during tree construction. If a sample has a missing value for the best splitting feature, the algorithm can try a secondary \"surrogate\" split based on a different feature that correlates well with the primary splitting feature.\n",
        "\n",
        "For example, suppose a decision tree splits on feature\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  (say, age), but some instances have missing values for\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        " . The algorithm could look for another feature\n",
        "𝑋\n",
        "2\n",
        "X\n",
        "2\n",
        "​\n",
        "  (say, income) that also correlates with\n",
        "𝑋\n",
        "1\n",
        "X\n",
        "1\n",
        "​\n",
        "  and use that to decide how to split these instances.\n",
        "\n",
        "4. Assigning Missing Values to a Specific Branch:\n",
        "In some implementations, missing values are treated as a separate category and assigned to a specific branch. This could lead to a split where samples with missing values go down a different path than those with observed values. This is a simple approach but might not always capture the underlying data structure.\n",
        "\n",
        "5. Probability-Based or Weighted Approach:\n",
        "In some cases, missing values can be handled probabilistically by distributing them across multiple branches based on probabilities. This can be useful in cases where the missingness is not random and is correlated with other features.\n",
        "\n",
        "Example in scikit-learn:\n",
        "In scikit-learn, the CART algorithm (which is commonly used for decision trees) doesn't inherently handle missing values. However, you can use imputation methods such as the SimpleImputer or KNNImputer to fill missing values before training a decision tree."
      ],
      "metadata": {
        "id": "MkLbQ3gbEUGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14"
      ],
      "metadata": {
        "id": "ywEDHcFXEUEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->1. Splitting on Categorical Features\n",
        "When a decision tree encounters a categorical feature during the splitting process, it must decide how to partition the data based on the categories.\n",
        "\n",
        "For binary categorical features (e.g., yes/no, true/false):\n",
        "The tree simply splits the data into two groups based on the categories (for example, \"yes\" and \"no\").\n",
        "\n",
        "For multi-class categorical features (e.g., colors: red, blue, green):\n",
        "The tree evaluates different ways to split the categories, often considering combinations of categories.\n",
        "\n",
        "The splitting criterion (like Gini impurity or entropy) helps determine the best way to partition the data.\n",
        "\n",
        "For example:\n",
        "\n",
        "If the feature is color with categories red, blue, and green, the tree might:\n",
        "\n",
        "Split by a condition like \"is the color red or not?\" (with a subset of categories combined).\n",
        "\n",
        "Or, it might consider splitting into two branches: one for \"red\" and the other for \"blue/green\" (if that produces a better separation of classes).\n",
        "\n",
        "2. Splitting Criteria (Gini Impurity, Information Gain)\n",
        "When deciding how to split, the decision tree uses certain criteria to measure the effectiveness of a split:\n",
        "\n",
        "For categorical features, the tree evaluates how well the categories split the data by checking how pure the resulting subsets are after the split. The common measures include:\n",
        "\n",
        "Gini Impurity: Measures the impurity of a node by calculating how often a randomly chosen element would be incorrectly classified if it were randomly labeled.\n",
        "\n",
        "Entropy (Information Gain): Measures the uncertainty in the data before and after the split. A split with higher information gain means it reduces uncertainty better.\n",
        "\n",
        "For example, if we are splitting a feature \"Color\" with values Red, Blue, Green, the tree would check which way of grouping (e.g., splitting as \"Red\" vs. \"Not Red\") reduces the impurity or uncertainty the most.\n",
        "\n",
        "3. Handling Multiple Categories\n",
        "When the categorical feature has many distinct categories (e.g., a \"City\" feature with 1000 cities), decision trees may use one of the following methods to handle them:\n",
        "\n",
        "One-hot encoding: Convert the categorical variable into a set of binary variables, one for each category. The decision tree then treats each new binary feature as a separate feature. However, this increases the dimensionality.\n",
        "\n",
        "Label encoding: Each category is assigned a numerical label (e.g., 1 for \"Red\", 2 for \"Blue\", etc.), but this can imply an artificial ordinal relationship between categories (which may not always make sense).\n",
        "\n",
        "Grouping categories: Sometimes, categories are combined or grouped based on domain knowledge or based on frequency (e.g., combining infrequent categories into an \"Other\" category).\n",
        "\n",
        "4. Advantages of Decision Trees with Categorical Features\n",
        "Interpretability: Decision trees work well with categorical data because they can easily produce human-readable decision rules (e.g., \"If color is red, then classify as X\").\n",
        "\n",
        "No need for scaling: Unlike algorithms like k-nearest neighbors (KNN) or support vector machines (SVM), decision trees do not require normalization or scaling of features.\n",
        "\n"
      ],
      "metadata": {
        "id": "IeBqjwJ-EUBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15"
      ],
      "metadata": {
        "id": "nLSSnUblET-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->Decision Trees are widely used in various real-world applications due to their simplicity, interpretability, and ability to handle both numerical and categorical data. Here are some key areas where Decision Trees are applied:\n",
        "\n",
        "1. Healthcare\n",
        "Diagnosis and Medical Predictions: Decision Trees are used to predict diseases based on symptoms, lab results, or other medical factors. For instance, they can help in predicting whether a patient has a certain disease like diabetes or heart disease based on input variables (age, blood pressure, cholesterol levels, etc.).\n",
        "\n",
        "Medical Treatment Decision Support: Doctors use decision trees to decide on treatment plans for patients. By considering factors like age, medical history, and current health status, the tree can recommend the best course of action (e.g., medication vs. surgery).\n",
        "\n",
        "2. Finance\n",
        "Credit Scoring and Risk Assessment: Financial institutions use Decision Trees to evaluate whether an individual or company is a good candidate for a loan or credit. Factors such as credit history, income level, employment status, and other financial factors are analyzed to predict the likelihood of loan default.\n",
        "\n",
        "Fraud Detection: Decision Trees help in detecting fraudulent activities. They can learn from past instances of fraudulent and non-fraudulent transactions and classify new transactions based on patterns found in the data.\n",
        "\n",
        "Stock Market Prediction: They are used in predicting stock price movements by evaluating historical data, market trends, and other relevant indicators.\n",
        "\n",
        "3. Marketing\n",
        "Customer Segmentation: Decision Trees are commonly used to segment customers based on their purchasing behavior, demographic data, or browsing activity. This helps businesses to target specific customer groups with personalized marketing campaigns.\n",
        "\n",
        "Lead Scoring: In sales and marketing, Decision Trees can help prioritize leads based on their likelihood to convert into customers, based on factors like age, interest, past behavior, etc.\n",
        "\n",
        "Churn Prediction: Companies use Decision Trees to predict customer churn (when a customer stops using a service). By analyzing past behavior, customer satisfaction, and other factors, companies can identify at-risk customers and take proactive steps to retain them.\n",
        "\n",
        "4. E-commerce\n",
        "Recommendation Systems: E-commerce websites use Decision Trees to make product recommendations based on customer preferences, purchase history, and browsing patterns.\n",
        "\n",
        "Price Optimization: Decision Trees help companies optimize pricing strategies by considering various factors like competitor prices, demand trends, and customer price sensitivity.\n",
        "\n",
        "5. Manufacturing and Operations\n",
        "Quality Control: Decision Trees are used in manufacturing to predict product defects or identify factors that lead to defects, allowing businesses to improve quality control processes.\n",
        "\n",
        "Predictive Maintenance: By analyzing sensor data from machines and equipment, Decision Trees can predict potential failures and schedule maintenance before a breakdown occurs, thus reducing downtime and repair costs.\n",
        "\n",
        "6. Retail\n",
        "Inventory Management: Retailers use Decision Trees to optimize inventory levels based on factors like seasonality, sales trends, and customer demand. This helps in reducing both stockouts and overstock situations.\n",
        "\n",
        "Sales Forecasting: Decision Trees help predict future sales by considering historical sales data, promotional events, economic conditions, and other relevant factors.\n",
        "\n",
        "7. Agriculture\n",
        "Crop Prediction and Yield Estimation: Decision Trees can help predict crop yields based on factors like weather patterns, soil conditions, irrigation practices, and pest management. This allows farmers to make better decisions about when to plant, irrigate, or harvest crops.\n",
        "\n",
        "Disease and Pest Detection: Decision Trees can be trained to detect diseases and pests in crops by analyzing various environmental and biological factors.\n",
        "\n",
        "8. Energy\n",
        "Energy Consumption Forecasting: Decision Trees are used to predict energy demand based on weather conditions, time of day, historical data, and other factors, helping energy companies optimize their supply and reduce waste.\n",
        "\n",
        "Fault Detection in Power Grid Systems: They can help in detecting faults in electrical grid systems by analyzing historical data from various sensors, enabling faster response times and reduced downtime.\n",
        "\n",
        "9. Insurance\n",
        "Claim Prediction and Underwriting: Insurance companies use Decision Trees to predict the likelihood of an individual filing a claim based on variables like age, health history, or driving record. This is also used for pricing insurance policies.\n",
        "\n",
        "Risk Assessment: Decision Trees can help insurers assess risk for different types of policies (life, health, car, etc.) and determine appropriate premiums for policyholders.\n",
        "\n",
        "10. Sports\n",
        "Player Performance Analysis: Decision Trees can be used to analyze player performance based on historical data (e.g., average score, fitness level, injury history) to make predictions about future performance or help in team selection.\n",
        "\n",
        "Game Strategy Optimization: Coaches and analysts use Decision Trees to optimize game strategies by evaluating historical game data, team dynamics, and opponent strengths/weaknesses.\n",
        "\n",
        "11. Natural Language Processing (NLP)\n",
        "Text Classification: Decision Trees are applied in classifying text documents into categories (e.g., spam vs. not spam, topic categorization).\n",
        "\n",
        "Sentiment Analysis: Decision Trees can be used to determine the sentiment (positive, negative, or neutral) of a piece of text, such as customer reviews or social media posts.\n",
        "\n",
        "12. Autonomous Systems\n",
        "Self-Driving Cars: Decision Trees help in making driving decisions, such as whether to stop, go, or turn, based on real-time data from sensors (e.g., distance from objects, speed, road conditions).\n",
        "\n"
      ],
      "metadata": {
        "id": "mJTTw3PXEXOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "LtQULPX7Eo5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1"
      ],
      "metadata": {
        "id": "FjtTKexSEo2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uPx4ICCE1_L",
        "outputId": "c253aa45-0c9c-4426-b999-ee548706e690"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2"
      ],
      "metadata": {
        "id": "jF0rcY8QEoz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Gini Impurity as the criterion\n",
        "dt_classifier = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Print the feature importances\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, dt_classifier.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOjdsMbQE2hT",
        "outputId": "9e8cf80b-0cf7-4049-e52a-14d4282430bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "JAIvg8CvEoxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Entropy as the splitting criterion\n",
        "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw6fmqxdE21b",
        "outputId": "1859280d-b8ac-498a-89ad-04a9bd36272a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4"
      ],
      "metadata": {
        "id": "n2eM-7vcEouj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target values (house prices)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the regressor on the training data\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dt_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the MSE\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAjG4PkaE3Ni",
        "outputId": "2dd682e0-5186-4d9b-e7f6-df5d33131a08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5"
      ],
      "metadata": {
        "id": "Ls3X5-qYEorz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the trained decision tree using Graphviz\n",
        "dot_data = export_graphviz(dt_classifier, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Create a Graphviz source object and render it\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_decision_tree\", view=True)  # This will save and open the visualization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q9kYUezvE4Qz",
        "outputId": "7f8cca81-6962-459b-f3ad-bd4bd1b68f51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6"
      ],
      "metadata": {
        "id": "hawOE0nTEoo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with max depth of 3\n",
        "dt_classifier_max_depth_3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "\n",
        "# Train the classifier with max depth 3\n",
        "dt_classifier_max_depth_3.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_max_depth_3 = dt_classifier_max_depth_3.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for max depth 3\n",
        "accuracy_max_depth_3 = accuracy_score(y_test, y_pred_max_depth_3)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with no max depth (fully grown tree)\n",
        "dt_classifier_full_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier with no max depth (fully grown tree)\n",
        "dt_classifier_full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_full_tree = dt_classifier_full_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the fully grown tree\n",
        "accuracy_full_tree = accuracy_score(y_test, y_pred_full_tree)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of Decision Tree with max depth 3: {accuracy_max_depth_3 * 100:.2f}%\")\n",
        "print(f\"Accuracy of fully grown Decision Tree: {accuracy_full_tree * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtKcREViE4qS",
        "outputId": "6d8b6baa-5120-4ae5-dd78-94b16e0fd7fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree with max depth 3: 100.00%\n",
            "Accuracy of fully grown Decision Tree: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7"
      ],
      "metadata": {
        "id": "S60-B3CrEomL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with min_samples_split=5\n",
        "dt_classifier_min_samples_split_5 = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "\n",
        "# Train the classifier with min_samples_split=5\n",
        "dt_classifier_min_samples_split_5.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_min_samples_split_5 = dt_classifier_min_samples_split_5.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the min_samples_split=5 tree\n",
        "accuracy_min_samples_split_5 = accuracy_score(y_test, y_pred_min_samples_split_5)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with the default parameters\n",
        "dt_classifier_default = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier with default settings\n",
        "dt_classifier_default.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_default = dt_classifier_default.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the default tree\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of Decision Tree with min_samples_split=5: {accuracy_min_samples_split_5 * 100:.2f}%\")\n",
        "print(f\"Accuracy of default Decision Tree: {accuracy_default * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRtD3CROE5Ij",
        "outputId": "17f45245-6161-488e-d290-1abfa4386a61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree with min_samples_split=5: 100.00%\n",
            "Accuracy of default Decision Tree: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8"
      ],
      "metadata": {
        "id": "qfJwqWP0EojX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on unscaled data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_unscaled = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy for the unscaled data\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# Apply feature scaling (Standardization) to the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the classifier on scaled data\n",
        "dt_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_scaled = dt_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy for the scaled data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the accuracies for comparison\n",
        "print(f\"Accuracy of Decision Tree on unscaled data: {accuracy_unscaled * 100:.2f}%\")\n",
        "print(f\"Accuracy of Decision Tree on scaled data: {accuracy_scaled * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79RvDnhiE5lL",
        "outputId": "b9992353-6213-4333-aa53-6e04b08fc941"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree on unscaled data: 100.00%\n",
            "Accuracy of Decision Tree on scaled data: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9"
      ],
      "metadata": {
        "id": "biIdnVL7EogT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the One-vs-Rest classifier with the Decision Tree as the base estimator\n",
        "ovr_classifier = OneVsRestClassifier(dt_classifier)\n",
        "\n",
        "# Train the One-vs-Rest classifier on the training data\n",
        "ovr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = ovr_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy of Decision Tree with One-vs-Rest strategy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH4isUMgE6d0",
        "outputId": "0eab1601-c873-4442-bf45-3b78bc8fc475"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree with One-vs-Rest strategy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10"
      ],
      "metadata": {
        "id": "a7URmvy0Eodb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get the feature importance scores\n",
        "feature_importances = dt_classifier.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display the features and their importance scores\n",
        "feature_names = iris.feature_names\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance scores\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGVVqeXE63z",
        "outputId": "0f9b4d4c-d1ea-4f10-bdfa-f6a508ee5652"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "             Feature  Importance\n",
            "2  petal length (cm)    0.893264\n",
            "3   petal width (cm)    0.087626\n",
            "1   sepal width (cm)    0.019110\n",
            "0  sepal length (cm)    0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11"
      ],
      "metadata": {
        "id": "YhI2OPK9Eoaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable (median house values)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor with max_depth=5\n",
        "dt_regressor_max_depth_5 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "\n",
        "# Train the model with max_depth=5\n",
        "dt_regressor_max_depth_5.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_max_depth_5 = dt_regressor_max_depth_5.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error for the max_depth=5 model\n",
        "mse_max_depth_5 = mean_squared_error(y_test, y_pred_max_depth_5)\n",
        "\n",
        "# Initialize the Decision Tree Regressor without depth limit (fully grown tree)\n",
        "dt_regressor_full_tree = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model with no depth limit\n",
        "dt_regressor_full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_full_tree = dt_regressor_full_tree.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error for the fully grown tree\n",
        "mse_full_tree = mean_squared_error(y_test, y_pred_full_tree)\n",
        "\n",
        "# Print the Mean Squared Errors for comparison\n",
        "print(f\"Mean Squared Error for Decision Tree with max_depth=5: {mse_max_depth_5:.2f}\")\n",
        "print(f\"Mean Squared Error for fully grown Decision Tree: {mse_full_tree:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FMrdPhDE7YM",
        "outputId": "41355afa-a566-4280-d91a-744a5d03f3de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for Decision Tree with max_depth=5: 0.52\n",
            "Mean Squared Error for fully grown Decision Tree: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12"
      ],
      "metadata": {
        "id": "IldJ_eX2EoXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize a Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the decision tree without pruning\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set without pruning\n",
        "y_pred_unpruned = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the unpruned tree\n",
        "accuracy_unpruned = accuracy_score(y_test, y_pred_unpruned)\n",
        "\n",
        "# Get the effective alphas (values of ccp_alpha)\n",
        "path = dt_classifier.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "impurities = path.impurities\n",
        "\n",
        "# Train Decision Trees for different values of ccp_alpha (pruned trees)\n",
        "accuracies = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    # Initialize a new Decision Tree Classifier with a specific ccp_alpha\n",
        "    dt_classifier_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "\n",
        "    # Train the classifier\n",
        "    dt_classifier_pruned.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_pruned = dt_classifier_pruned.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy for the pruned tree\n",
        "    accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
        "    accuracies.append(accuracy_pruned)\n",
        "\n",
        "# Plot the effect of CCP pruning on accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, accuracies, marker='o', label=\"Accuracy of pruned trees\")\n",
        "plt.axhline(accuracy_unpruned, linestyle='--', color='r', label=\"Accuracy of unpruned tree\")\n",
        "plt.xlabel(\"ccp_alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of Cost Complexity Pruning on Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print the best ccp_alpha and the corresponding accuracy\n",
        "best_ccp_alpha = ccp_alphas[accuracies.index(max(accuracies))]\n",
        "best_accuracy = max(accuracies)\n",
        "print(f\"Best ccp_alpha: {best_ccp_alpha:.5f}, Accuracy: {best_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "kDAulyfkE78b",
        "outputId": "546cb61e-6081-4b6d-ebaf-2b70be53eca3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ccp_alpha: 0.00000, Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13"
      ],
      "metadata": {
        "id": "Y2X4wqYoEoUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate performance using Precision, Recall, and F1-Score for each class\n",
        "precision = precision_score(y_test, y_pred, average=None)  # Precision for each class\n",
        "recall = recall_score(y_test, y_pred, average=None)        # Recall for each class\n",
        "f1 = f1_score(y_test, y_pred, average=None)                # F1-Score for each class\n",
        "\n",
        "# Display the metrics for each class\n",
        "print(\"Precision for each class:\", precision)\n",
        "print(\"Recall for each class:\", recall)\n",
        "print(\"F1-Score for each class:\", f1)\n",
        "\n",
        "# Display the overall classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4-JtHBEE8Rj",
        "outputId": "acea324c-e1d3-48db-c0fc-648d479a7d96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for each class: [1. 1. 1.]\n",
            "Recall for each class: [1. 1. 1.]\n",
            "F1-Score for each class: [1. 1. 1.]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      1.00      1.00        13\n",
            "   virginica       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14"
      ],
      "metadata": {
        "id": "zbtUae_tEoSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using a heatmap from seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.title(\"Confusion Matrix for Decision Tree Classifier\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "TSaNXip3E8wz",
        "outputId": "d952236c-4b74-4e6d-aacf-95ddc7af999e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15"
      ],
      "metadata": {
        "id": "Z1hjd-fCEoLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],  # Different values for max_depth\n",
        "    'min_samples_split': [2, 5, 10]  # Different values for min_samples_split\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with Decision Tree Classifier and the parameter grid\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters found by GridSearchCV: {best_params}\")\n",
        "\n",
        "# Get the best estimator (classifier) with optimal parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the best model on the test set: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm0uyjtbE9Er",
        "outputId": "d658929b-0bf8-4da0-c342-daf8cd7a7198"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found by GridSearchCV: {'max_depth': 5, 'min_samples_split': 10}\n",
            "Accuracy of the best model on the test set: 1.0000\n"
          ]
        }
      ]
    }
  ]
}